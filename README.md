# Whisper besz√©d felismer≈ë modell finomhangol√°sa √©s gyors√≠tott k√∂vetkeztet√©s

Egyszer≈±s√≠tett k√≠nai | [English](./README_en.md)

![python version](https://img.shields.io/badge/python-3.8+-orange.svg)
![GitHub forks](https://img.shields.io/github/forks/shuaijiang/Whisper-Finetune)
![GitHub Repo stars](https://img.shields.io/github/stars/shuaijiang/Whisper-Finetune)
![GitHub](https://img.shields.io/github/license/shuaijiang/Whisper-Finetune)
[![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging_Face-BELLE--Whisper-blue.svg)](https://huggingface.co/BELLE-2)
![T√°mogatott rendszerek](https://img.shields.io/badge/T√°mogatott%20rendszerek-Win/Linux/MAC-9cf)

## El≈ësz√≥

Az OpenAI ny√≠lt forr√°sk√≥d√∫v√° tette a Whisper projektet, amely √°ll√≠t√°suk szerint emberi szint≈± angol besz√©dfelismer√©si k√©pess√©gekkel rendelkezik, √©s tov√°bbi 98 nyelv automatikus besz√©dfelismer√©s√©t is t√°mogatja. A Whisper automatikus besz√©dfelismer√©si √©s ford√≠t√°si feladatokat k√≠n√°l, amelyek k√©pesek k√ºl√∂nb√∂z≈ë nyelvek besz√©d√©t sz√∂vegg√© alak√≠tani, valamint ezeket a sz√∂vegeket angolra ford√≠tani. Ennek a projektnek a f≈ë c√©lja a Whisper modell finomhangol√°sa a Lora seg√≠ts√©g√©vel, **t√°mogatva az id≈ëb√©lyeg n√©lk√ºli adatokkal t√∂rt√©n≈ë tan√≠t√°st, az id≈ëb√©lyeggel rendelkez≈ë adatokkal t√∂rt√©n≈ë tan√≠t√°st √©s a besz√©dadatok n√©lk√ºli tan√≠t√°st**. Jelenleg t√∂bb modell is ny√≠lt forr√°sk√≥d√∫, amelyeket az [openai](https://huggingface.co/openai) oldalon lehet megtekinteni. Az al√°bbiakban felsorolunk n√©h√°ny gyakran haszn√°lt modellt. Ezenk√≠v√ºl a projekt t√°mogatja a CTranslate2 gyors√≠tott k√∂vetkeztet√©st √©s a GGML gyors√≠tott k√∂vetkeztet√©st is. Megjegyz√©s: a gyors√≠tott k√∂vetkeztet√©s t√°mogatja a Whisper eredeti modellj√©nek k√∂zvetlen konvert√°l√°s√°t, nem felt√©tlen√ºl sz√ºks√©ges a finomhangol√°s. T√°mogatja a Windows asztali alkalmaz√°sokat, az Android alkalmaz√°sokat √©s a szerveroldali telep√≠t√©st.

### K√©rlek, el≈ësz√∂r csillagozd meg :star:
## üîÑ Leg√∫jabb friss√≠t√©sek
* [2025/03/26] Tov√°bbfejlesztett√ºk a visszhang hozz√°ad√°sa funkci√≥t [Add reverb](https://github.com/shuaijiang/Whisper-Finetune/blob/master/docs/robust_asr.md#Add-reverb), n√∂velve a besz√©dfelismer√©s robusztuss√°g√°t.
* [2024/12/16] Tov√°bbfejlesztett√ºk a ggml modell konvert√°l√°si funkci√≥t [convert-ggml](https://github.com/shuaijiang/Whisper-Finetune/tree/master/convert-ggml), t√°mogatva a whisper.cpp-t.
* [2024/11/18] √öj spektr√°lis augment√°ci√≥s [SpecAugment](https://github.com/shuaijiang/Whisper-Finetune/blob/master/docs/robust_asr.md#SpecAugment) funkci√≥ hozz√°ad√°sa, amely hat√©konyan n√∂veli a besz√©dfelismer√©s robusztuss√°g√°t.
* [2024/10/16] Kiadtuk a [Belle-whisper-large-v3-turbo-zh](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-turbo-zh) modellt, amely a whisper-large-v3-turbo alap√∫, jav√≠tott k√≠nai felismer√©si k√©pess√©gekkel (bele√©rtve az √≠r√°sjeleket), jelent≈ësen jav√≠tott k√≠nai felismer√©si k√©pess√©ggel (24-64%-os relat√≠v javul√°s) √©s 7-8-szoros sebess√©gn√∂veked√©ssel.
* [2024/06/11] Kiadtuk a [Belle-whisper-large-v3-zh-punct](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-zh-punct) modellt, amely a Belle-whisper-large-v3 alap√∫, jav√≠tott k√≠nai √≠r√°sjel-felismer√©si k√©pess√©gekkel, mik√∂zben a komplex jelenetek felismer√©si k√©pess√©ge tov√°bb javult.
* [2024/03/11] Kiadtuk a [Belle-whisper-large-v3-zh](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-zh) modellt, amely a whisper-large-v3 alap√∫, jav√≠tott k√≠nai felismer√©si k√©pess√©gekkel, jelent≈ësen jav√≠tott komplex jelenetek felismer√©si k√©pess√©ggel.
* [2023/12/29] Kiadtuk a [Belle-whisper-large-v2-zh](https://huggingface.co/BELLE-2/Belle-whisper-large-v2-zh) modellt, amely a whisper-large-v2 alap√∫, jav√≠tott k√≠nai felismer√©si k√©pess√©gekkel, jelent≈ësen jav√≠tott k√≠nai felismer√©si k√©pess√©ggel.
* [2023/12/29] Kiadtuk a [Belle-distilwhisper-large-v2-zh](https://huggingface.co/BELLE-2/Belle-distilwhisper-large-v2-zh) modellt, amely a distilwhisper-large-v2 alap√∫, jav√≠tott k√≠nai felismer√©si k√©pess√©gekkel, egyens√∫lyt teremtve a sebess√©g √©s a pontoss√°g k√∂z√∂tt.

## T√°mogatott modellek

- openai/whisper-large-v2
- openai/whisper-large-v3
- openai/whisper-large-v3-turbo
- distil-whisper

**Haszn√°lati k√∂rnyezet:**

- Anaconda 3
- Python 3.10
- Pytorch 2.1.0
- GPU A100-PCIE-80GB


## Tartalomjegyz√©k
 - [A projekt f≈ë programjainak bemutat√°sa](#a-projekt-f≈ë-programjainak-bemutat√°sa)
 - [Modell le√≠r√°sa](#modell-le√≠r√°sa)
 - [Modell teljes√≠tm√©nye](#modell-teljes√≠tm√©nye)
 - [K√∂rnyezet telep√≠t√©se](#k√∂rnyezet-telep√≠t√©se)
 - [Adatok el≈ëk√©sz√≠t√©se](#adatok-el≈ëk√©sz√≠t√©se)
 - [Modell finomhangol√°sa](#modell-finomhangol√°sa)
   - [Egyk√°rty√°s tan√≠t√°s](#egyk√°rty√°s-tan√≠t√°s)
   - [T√∂bbk√°rty√°s tan√≠t√°s](#t√∂bbk√°rty√°s-tan√≠t√°s)
 - [Modellek egyes√≠t√©se](#modellek-egyes√≠t√©se)
 - [Modell √©rt√©kel√©se](#modell-√©rt√©kel√©se)
 - [Predikci√≥](#predikci√≥)
 - [Gyors√≠tott predikci√≥](#gyors√≠tott-predikci√≥)
 - [GUI fel√ºletes predikci√≥](#gui-fel√ºletes-predikci√≥)
 - [Webes telep√≠t√©s](#webes-telep√≠t√©s)
   - [API dokument√°ci√≥](#api-dokument√°ci√≥)
 - [Android telep√≠t√©s](#android-telep√≠t√©s)
 - [Windows asztali alkalmaz√°s](#windows-asztali-alkalmaz√°s)

<a name='a-projekt-f≈ë-programjainak-bemutat√°sa'></a>

## A projekt f≈ë programjainak bemutat√°sa

1. `aishell.py`: AIShell tan√≠t√°si adatok k√©sz√≠t√©se.
2. `finetune.py`: PEFT m√≥dszerrel t√∂rt√©n≈ë modell finomhangol√°s.
3. `finetune_all.py`: Teljes param√©teres modell finomhangol√°s.
4. `merge_lora.py`: Whisper √©s Lora modellek egyes√≠t√©se.
5. `evaluation.py`: Finomhangolt vagy eredeti Whisper modell √©rt√©kel√©se.
6. `infer_tfs.py`: Transformers haszn√°lata finomhangolt vagy eredeti Whisper modell predikci√≥j√°hoz, csak r√∂vid hanganyagokhoz alkalmas.
7. `infer_ct2.py`: CTranslate2-re konvert√°lt modell haszn√°lata predikci√≥hoz, f≈ëk√©nt ennek a programnak a haszn√°lata aj√°nlott.
8. `infer_gui.py`: GUI fel√ºlettel rendelkez≈ë m≈±velet, CTranslate2-re konvert√°lt modell haszn√°lata predikci√≥hoz.
9. `infer_server.py`: CTranslate2-re konvert√°lt modell szerveroldali telep√≠t√©se, kliensoldali h√≠v√°sokhoz.
10. `convert-ggml.py`: Modell konvert√°l√°sa GGML form√°tumba, Android vagy Windows alkalmaz√°sokhoz.
11. `AndroidDemo`: Ez a k√∂nyvt√°r tartalmazza a modell Androidra t√∂rt√©n≈ë telep√≠t√©s√©nek forr√°sk√≥dj√°t.
12. `WhisperDesktop`: Ez a k√∂nyvt√°r tartalmazza a Windows asztali alkalmaz√°s programj√°t.


<a name='modell-le√≠r√°sa'></a>
## Modell le√≠r√°sa
|       Modell      | Param√©terek (M) | Alapmodell | Adat (√öjra)mintav√©telez√©si r√°ta |                      Tan√≠t√°si adathalmazok         | Finomhangol√°s (teljes vagy peft) |
|:----------------:|:-------:|:-------:|:-------:|:----------------------------------------------------------:|:-----------:|
| Belle-whisper-large-v2-zh | 1550 |whisper-large-v2| 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   teljes finomhangol√°s   |
| Belle-distil-whisper-large-v2-zh | 756 | distil-whisper-large-v2 | 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   teljes finomhangol√°s    |
| Belle-whisper-large-v3-zh | 1550 |whisper-large-v3 | 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   teljes finomhangol√°s   |
| Belle-whisper-large-v3-zh-punct | 1550 | Belle-whisper-large-v3-zh | 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   lora finomhangol√°s   |
| Belle-whisper-large-v3-turbo-zh | 809 | Belle-whisper-large-v3-turbo | 16KHz | [AISHELL-1](https://openslr.magicdatatech.com/resources/33/) [AISHELL-2](https://www.aishelltech.com/aishell_2) [WenetSpeech](https://wenet.org.cn/WenetSpeech/) [HKUST](https://catalog.ldc.upenn.edu/LDC2005S15)  |   teljes finomhangol√°s   |
<a name='modell-teljes√≠tm√©nye'></a>

## Modell teljes√≠tm√©nye CER(%) ‚Üì
|      Modell       |  Nyelvi c√≠mke   | aishell_1 teszt |aishell_2 teszt| wenetspeech test_net | wenetspeech test_meeting | HKUST_dev| Modell link |
|:----------------:|:-------:|:-----------:|:-----------:|:--------:|:-----------:|:-------:|:-------:|
| whisper-large-v3-turbo | K√≠nai |   8.639    | 6.014 |   13.507   | 20.313 | 37.324 |[HF](https://huggingface.co/openai/whisper-large-v3-turbo) |
| Belle-whisper-large-v3-turbo-zh | K√≠nai |   3.070    | 4.114 |   10.230   | 13.357 | 18.944 |[HF](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-turbo-zh) |
| whisper-large-v2 | K√≠nai |   8.818   | 6.183  |   12.343  |  26.413  | 31.917 | [HF](https://huggingface.co/openai/whisper-large-v2)|
| Belle-whisper-large-v2-zh | K√≠nai |   **2.549**    | **3.746**  |   **8.503**   | 14.598 | **16.289** |[HF](https://huggingface.co/BELLE-2/Belle-whisper-large-v2-zh) |
| whisper-large-v3 | K√≠nai |   8.085   | 5.475  |   11.72  |  20.15  | 28.597 | [HF](https://huggingface.co/openai/whisper-large-v3)|
| Belle-whisper-large-v3-zh | K√≠nai |   2.781    | 3.786 |   8.865   | 11.246 | 16.440 |[HF](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-zh) |
| Belle-whisper-large-v3-zh-punct | K√≠nai |   2.945    | 3.808 |   8.998   | **10.973** | 17.196 |[HF](https://huggingface.co/BELLE-2/Belle-whisper-large-v3-zh-punct) |
| distil-whisper-large-v2 | K√≠nai |  -    | -  |   -  | - | -|[HF](https://huggingface.co/distil-whisper/distil-large-v2) |
| Belle-distilwhisper-large-v2-zh | K√≠nai |  5.958   | 6.477  |   12.786    | 17.039 | 20.771 | [HF](https://huggingface.co/BELLE-2/Belle-distilwhisper-large-v2-zh) |



**Fontos megjegyz√©sek:**
1. Az √©rt√©kel√©s sor√°n t√°vol√≠tsa el a modell kimenet√©b≈ël az √≠r√°sjeleket, √©s alak√≠tsa √°t a hagyom√°nyos k√≠nai karaktereket egyszer≈±s√≠tett k√≠naira.
2. Az `aishell_1_test` az AIShell-1 tesztk√©szlete, az `aishell_2_test` az AIShell-2 tesztk√©szlete, a `test_net` √©s a `test_meeting` a WenetSpeech tesztk√©szletei.
3. A distil-whisper-large-v2 angol adatokon alapul√≥ desztill√°ci√≥, csak angol kimenetet tud produk√°lni. Fontos megjegyezni, hogy az eredeti distil-whisper-large-v2 nem tud k√≠naiul √°t√≠rni (csak angolul ad ki).
4. A Belle-whisper-large-v3-zh a Belle-whisper-large-v2-zh-hoz k√©pest jelent≈ës el≈ënnyel rendelkezik komplex jelenetekben, jobb eredm√©nyeket √©r el a wenetspeech meetingen, 22%-os relat√≠v javul√°ssal.
5. A Belle-whisper-large-v3-zh-punct rendelkezik √≠r√°sjel-felismer√©si k√©pess√©ggel, az √≠r√°sjelek a [punc_ct-transformer_cn-en-common-vocab471067-large](https://www.modelscope.cn/models/iic/punc_ct-transformer_cn-en-common-vocab471067-large/) modellb≈ël sz√°rmaznak. Ezenk√≠v√ºl a komplex jelenetek hat√©konys√°ga tov√°bb javult.
6. A Belle-whisper-large-v3-turbo-zh a whisper-large-v3-turbo-hoz k√©pest 24-64%-os relat√≠v javul√°st mutat, a Belle-whisper-large-v3-zh-punct-hoz k√©pest enyhe pontoss√°gcs√∂kken√©s tapasztalhat√≥, de 7-8-szoros sebess√©gn√∂veked√©ssel rendelkezik, ami jelent≈ës alkalmaz√°si √©rt√©ket k√©pvisel korl√°tozott sz√°m√≠t√°si kapacit√°s mellett.
<a name='k√∂rnyezet-telep√≠t√©se'></a>

## K√∂rnyezet telep√≠t√©se

- El≈ësz√∂r telep√≠tse a Pytorch GPU verzi√≥j√°t. Az al√°bbiakban k√©tf√©le m√≥don telep√≠theti a Pytorch-ot, csak v√°lasszon egyet.

1. Az al√°bbiakban az Anaconda haszn√°lat√°val t√∂rt√©n≈ë Pytorch k√∂rnyezet telep√≠t√©se l√°that√≥, ha m√°r telep√≠tette, hagyja ki ezt a l√©p√©st.
```shell
conda install pytorch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1 pytorch-cuda=11.6 -c pytorch -c nvidia
```

2. Az al√°bbiakban Docker image haszn√°lata l√°that√≥, h√∫zzon le egy Pytorch k√∂rnyezet image-et.
```shell
sudo docker pull pytorch/pytorch:1.13.1-cuda11.6-cudnn8-devel
```

Ezut√°n l√©pjen be az image-be, √©s csatolja az aktu√°lis el√©r√©si utat a kont√©ner `/workspace` k√∂nyvt√°r√°hoz.
```shell
sudo nvidia-docker run --name pytorch -it -v $PWD:/workspace pytorch/pytorch:1.13.1-cuda11.6-cudnn8-devel /bin/bash
```

- Telep√≠tse a sz√ºks√©ges f√ºgg≈ës√©gi k√∂nyvt√°rakat.

```shell
python -m pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
```

- Windows eset√©n k√ºl√∂n kell telep√≠teni a bitsandbytes-ot.
```shell
python -m pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.40.1.post1-py3-none-win_amd64.whl
```

<a name='adatok-el≈ëk√©sz√≠t√©se'></a>

## Adatok el≈ëk√©sz√≠t√©se

A tan√≠t√°si adathalmaz a k√∂vetkez≈ë, egy jsonlines adatlista, azaz minden sor egy JSON adat, az adatform√°tum a k√∂vetkez≈ë. Ez a projekt biztos√≠t egy programot (`aishell.py`) az AIShell adathalmaz elk√©sz√≠t√©s√©hez, ennek a programnak a futtat√°sa automatikusan let√∂lti √©s l√©trehozza a k√∂vetkez≈ë form√°tum√∫ tan√≠t√°si √©s tesztel√©si adathalmazokat. **Megjegyz√©s:** Ez a program megadhatja az AIShell t√∂m√∂r√≠tett f√°jlj√°t a let√∂lt√©si folyamat kihagy√°s√°hoz. Ha k√∂zvetlen√ºl t√∂lti le, az nagyon lass√∫ lehet. Haszn√°lhat olyan let√∂lt≈ëket, mint a Xunlei, a adathalmaz let√∂lt√©s√©hez, majd a `--filepath` param√©terrel adja meg a let√∂lt√∂tt t√∂m√∂r√≠tett f√°jl el√©r√©si √∫tj√°t, p√©ld√°ul `/home/test/data_aishell.tgz`.

**Tippek:**
1. Ha nem haszn√°l id≈ëb√©lyegeket a tan√≠t√°shoz, akkor nem kell tartalmaznia a `sentences` mez≈ët.
2. Ha csak egy nyelven vannak adatok, akkor nem kell tartalmaznia a `language` mez≈ët.
3. Ha √ºres besz√©dadatokat tan√≠t, a `sentences` mez≈ë `[]`, a `sentence` mez≈ë `""`, √©s a `language` mez≈ë nem l√©tezhet.
4. Az adatok nem felt√©tlen√ºl tartalmaznak √≠r√°sjeleket, de a finomhangolt modell elvesz√≠theti az √≠r√°sjel-hozz√°ad√°si k√©pess√©g√©t.

```json
{
   "audio": {
      "path": "dataset/0.wav"
   },
   "sentence": "Az elm√∫lt √©vekben nemcsak √©n adtam k√∂nyvet a l√°nyomnak √∫j√©vi aj√°nd√©kk√©nt, hanem a rokonokat √©s bar√°tokat is meggy≈ëztem, hogy ne adjanak p√©nzt a l√°nyomnak, hanem adjanak k√∂nyvet.",
   "language": "Chinese",
   "sentences": [
      {
         "start": 0,
         "end": 1.4,
         "text": "Az elm√∫lt √©vekben,"
      },
      {
         "start": 1.42,
         "end": 8.4,
         "text": "nemcsak √©n adtam k√∂nyvet a l√°nyomnak √∫j√©vi aj√°nd√©kk√©nt, hanem a rokonokat √©s bar√°tokat is meggy≈ëztem, hogy ne adjanak p√©nzt a l√°nyomnak, hanem adjanak k√∂nyvet."
      }
   ],
   "duration": 7.37
}
```

<a name='modell-finomhangol√°sa'></a>

## Modell finomhangol√°sa

Az adatok el≈ëk√©sz√≠t√©se ut√°n megkezdheti a modell finomhangol√°s√°t. A tan√≠t√°s k√©t legfontosabb param√©tere a k√∂vetkez≈ë: `--base_model` megadja a finomhangoland√≥ Whisper modellt, ennek az √©rt√©knek l√©teznie kell a [HuggingFace](https://huggingface.co/openai) oldalon. Ezt nem kell el≈ëre let√∂lteni, a tan√≠t√°s ind√≠t√°sakor automatikusan let√∂lt≈ëdik. Term√©szetesen el≈ëre is let√∂ltheti, ebben az esetben a `--base_model` az el√©r√©si utat adja meg, √©s a `--local_files_only` √©rt√©ke True legyen. A m√°sodik `--output_path` a tan√≠t√°s sor√°n mentett Lora ellen≈ërz≈ëpontok el√©r√©si √∫tja, mivel Lora-t haszn√°lunk a modell finomhangol√°s√°hoz. Ha elegend≈ë a mem√≥ria, a legjobb, ha a `--use_8bit` √©rt√©k√©t False-ra √°ll√≠tja, √≠gy a tan√≠t√°s sokkal gyorsabb lesz. Tov√°bbi param√©terek√©rt tekintse meg ezt a programot.

<a name='egyk√°rty√°s-tan√≠t√°s'></a>

### Egyk√°rty√°s tan√≠t√°s

Az egyk√°rty√°s tan√≠t√°si parancs a k√∂vetkez≈ë, Windows rendszeren nem kell hozz√°adni a `CUDA_VISIBLE_DEVICES` param√©tert.
```shell
CUDA_VISIBLE_DEVICES=0 python finetune.py --base_model=openai/whisper-tiny --output_dir=output/
```

<a name='t√∂bbk√°rty√°s-tan√≠t√°s'></a>

### T√∂bbk√°rty√°s tan√≠t√°s

A t√∂bbk√°rty√°s tan√≠t√°snak k√©t m√≥dja van: a torchrun √©s az accelerate. A fejleszt≈ëk a saj√°t szok√°saiknak megfelel≈ëen haszn√°lhatj√°k a megfelel≈ë m√≥dszert.

1. A torchrun haszn√°lata t√∂bbk√°rty√°s tan√≠t√°s ind√≠t√°s√°hoz, a parancs a k√∂vetkez≈ë, a `--nproc_per_node` param√©terrel adja meg a haszn√°lt grafikus k√°rty√°k sz√°m√°t.
```shell
torchrun --nproc_per_node=2 finetune.py --base_model=openai/whisper-tiny --output_dir=output/
```

2. Az accelerate haszn√°lata t√∂bbk√°rty√°s tan√≠t√°s ind√≠t√°s√°hoz, ha el≈ësz√∂r haszn√°lja az accelerate-et, konfigur√°lnia kell a tan√≠t√°si param√©tereket, az al√°bbiak szerint.

El≈ësz√∂r konfigur√°lja a tan√≠t√°si param√©tereket, a folyamat sor√°n a fejleszt≈ënek n√©h√°ny k√©rd√©sre kell v√°laszolnia, √°ltal√°ban az alap√©rtelmezett √©rt√©kek megfelel≈ëek, de n√©h√°ny param√©tert a t√©nyleges helyzetnek megfelel≈ëen kell be√°ll√≠tani.
```shell
accelerate config
```

A folyamat nagyj√°b√≥l √≠gy n√©z ki:
```
--------------------------------------------------------------------Milyen sz√°m√≠t√°si k√∂rnyezetben futtatja?
Ez a g√©p
--------------------------------------------------------------------Milyen t√≠pus√∫ g√©pet haszn√°l?
t√∂bb GPU-s
H√°ny k√ºl√∂nb√∂z≈ë g√©pet fog haszn√°lni (t√∂bb mint 1-et haszn√°ljon t√∂bbcsom√≥pontos tan√≠t√°shoz)? [1]:
Szeretn√© optimaliz√°lni a szkriptj√©t a torch dynamo seg√≠ts√©g√©vel? [igen/NEM]:
Szeretn√© haszn√°lni a DeepSpeed-et? [igen/NEM]:
Szeretn√© haszn√°lni a FullyShardedDataParallel-t? [igen/NEM]:
Szeretn√© haszn√°lni a Megatron-LM-et? [igen/NEM]:
H√°ny GPU-t kell haszn√°lni az elosztott tan√≠t√°shoz? [1]:2
Melyik GPU(ka)t (azonos√≠t√≥ szerint) kell haszn√°lni a tan√≠t√°shoz ezen a g√©pen vessz≈ëvel elv√°lasztott listak√©nt? [mind]:
--------------------------------------------------------------------Szeretne FP16-ot vagy BF16-ot haszn√°lni (vegyes pontoss√°g)?
fp16
az accelerate konfigur√°ci√≥ mentve a /home/test/.cache/huggingface/accelerate/default_config.yaml helyre
```

A konfigur√°l√°s befejez√©se ut√°n a k√∂vetkez≈ë paranccsal tekintheti meg a konfigur√°ci√≥t.
```shell
accelerate env
```

A tan√≠t√°s ind√≠t√°si parancsa a k√∂vetkez≈ë.
```shell
accelerate launch finetune.py --base_model=openai/whisper-tiny --output_dir=output/
```


A kimeneti napl√≥ a k√∂vetkez≈ë:
```shell
{'loss': 0.9098, 'learning_rate': 0.000999046843662503, 'epoch': 0.01}
{'loss': 0.5898, 'learning_rate': 0.0009970611012927184, 'epoch': 0.01}
{'loss': 0.5583, 'learning_rate': 0.0009950753589229333, 'epoch': 0.02}
{'loss': 0.5469, 'learning_rate': 0.0009930896165531485, 'epoch': 0.02}
{'loss': 0.5959, 'learning_rate': 0.0009911038741833634, 'epoch': 0.03}
```

<a name='modellek-egyes√≠t√©se'></a>

## Modellek egyes√≠t√©se

A PEFT m√≥dszerrel t√∂rt√©n≈ë modell finomhangol√°sa ut√°n k√©t modell lesz: az els≈ë a Whisper alapmodell, a m√°sodik a Lora modell. Ezt a k√©t modellt egyes√≠teni kell a tov√°bbi m≈±veletekhez. Ez a program csak k√©t param√©tert ig√©nyel: a `--lora_model` megadja a tan√≠t√°s ut√°n mentett Lora modell el√©r√©si √∫tj√°t, ami val√≥j√°ban az ellen≈ërz≈ëpont mappa el√©r√©si √∫tja, a m√°sodik `--output_dir` az egyes√≠tett modell ment√©si k√∂nyvt√°ra.
```shell
python merge_lora.py --lora_model=output/whisper-tiny/checkpoint-best/ --output_dir=models/
```

<a name='modell-√©rt√©kel√©se'></a>

## Modell √©rt√©kel√©se

Futtassa a k√∂vetkez≈ë programot a modell √©rt√©kel√©s√©hez. A k√©t legfontosabb param√©ter a k√∂vetkez≈ë: az els≈ë `--model_path` megadja az egyes√≠tett modell el√©r√©si √∫tj√°t, √©s t√°mogatja az eredeti Whisper modell k√∂zvetlen haszn√°lat√°t is, p√©ld√°ul k√∂zvetlen√ºl megadva az `openai/whisper-large-v2`-t. A m√°sodik `--metric` megadja az √©rt√©kel√©si m√≥dszert, p√©ld√°ul karakterhiba ar√°ny (`cer`) √©s sz√≥hiba ar√°ny (`wer`). **Tipp:** A nem finomhangolt modellek kimenete tartalmazhat √≠r√°sjeleket, ami befoly√°solhatja a pontoss√°got. Tov√°bbi param√©terek√©rt tekintse meg ezt a programot.
```shell
python evaluation.py --model_path=models/whisper-tiny-finetune --metric=cer
```

<a name='predikci√≥'></a>

## Predikci√≥

Futtassa a k√∂vetkez≈ë programot a besz√©dfelismer√©shez. Ez a transformers haszn√°lat√°val k√∂zvetlen√ºl h√≠vja a finomhangolt vagy eredeti Whisper modellt a predikci√≥hoz, csak r√∂vid hanganyagokhoz alkalmas, hossz√∫ hanganyagokhoz ink√°bb az `infer_ct2.py` haszn√°lata aj√°nlott. Az els≈ë `--audio_path` param√©ter megadja a predik√°land√≥ hanganyag el√©r√©si √∫tj√°t. A m√°sodik `--model_path` megadja az egyes√≠tett modell el√©r√©si √∫tj√°t, √©s t√°mogatja az eredeti Whisper modell k√∂zvetlen haszn√°lat√°t is, p√©ld√°ul k√∂zvetlen√ºl megadva az `openai/whisper-large-v2`-t. Tov√°bbi param√©terek√©rt tekintse meg ezt a programot.
```shell
python infer_tfs.py --audio_path=dataset/test.wav --model_path=models/whisper-tiny-finetune
```

<a name='gyors√≠tott-predikci√≥'></a>

## Gyors√≠tott predikci√≥

Mint ismeretes, a Whisper modell k√∂zvetlen haszn√°lata a k√∂vetkeztet√©shez viszonylag lass√∫, ez√©rt itt egy gyors√≠t√°si m√≥dszert k√≠n√°lunk, amely f≈ëk√©nt a CTranslate2-t haszn√°lja a gyors√≠t√°shoz. El≈ësz√∂r konvert√°lni kell a modellt, az egyes√≠tett modellt CTranslate2 modell√© kell alak√≠tani. Az al√°bbi parancsban a `--model` param√©ter megadja az egyes√≠tett modell el√©r√©si √∫tj√°t, √©s t√°mogatja az eredeti Whisper modell k√∂zvetlen haszn√°lat√°t is, p√©ld√°ul k√∂zvetlen√ºl megadva az `openai/whisper-large-v2`-t. A `--output_dir` param√©ter megadja a konvert√°lt CTranslate2 modell el√©r√©si √∫tj√°t. A `--quantization` param√©ter megadja a modell m√©ret√©nek kvant√°l√°s√°t, ha nem szeretn√© kvant√°lni a modellt, egyszer≈±en hagyja ki ezt a param√©tert.
```shell
ct2-transformers-converter --model models/whisper-tiny-finetune --output_dir models/whisper-tiny-finetune-ct2 --copy_files tokenizer.json --quantization float16
```

Futtassa a k√∂vetkez≈ë programot a gyors√≠tott besz√©dfelismer√©shez. Az `--audio_path` param√©ter megadja a predik√°land√≥ hanganyag el√©r√©si √∫tj√°t. A `--model_path` megadja a konvert√°lt CTranslate2 modellt. Tov√°bbi param√©terek√©rt tekintse meg ezt a programot.
```shell
python infer_ct2.py --audio_path=dataset/test.wav --model_path=models/whisper-tiny-finetune-ct2
```

A kimeneti eredm√©ny a k√∂vetkez≈ë:
```shell
-----------  Konfigur√°ci√≥s argumentumok -----------
audio_path: dataset/test.wav
model_path: models/whisper-tiny-finetune-ct2
language: zh
use_gpu: True
use_int8: False
beam_size: 10
num_workers: 1
vad_filter: False
local_files_only: True
------------------------------------------------
[0.0 - 8.0]ÔºöAz elm√∫lt √©vekben, nemcsak √©n adtam k√∂nyvet a l√°nyomnak aj√°nd√©kba, hanem a rokonokat √©s bar√°tokat is meggy≈ëztem, hogy ne adjanak p√©nzt a l√°nyomnak, hanem adjanak k√∂nyvet.
```

<a name='gui-fel√ºletes-predikci√≥'></a>

## GUI fel√ºletes predikci√≥

Itt is a CTranslate2-t haszn√°ljuk a gyors√≠t√°shoz, a modell konvert√°l√°s√°nak m√≥dj√°t l√°sd a fenti dokument√°ci√≥ban. A `--model_path` megadja a konvert√°lt CTranslate2 modellt. Tov√°bbi param√©terek√©rt tekintse meg ezt a programot.

```shell
python infer_gui.py --model_path=models/whisper-tiny-finetune-ct2
```

Ind√≠t√°s ut√°n a fel√ºlet a k√∂vetkez≈ë:

<div align="center">
<img src="./docs/images/gui.jpg" alt="GUI fel√ºlet" width="600"/>
</div>

<a name='webes-telep√≠t√©s'></a>

## Webes telep√≠t√©s

A webes telep√≠t√©shez is a CTranslate2-t haszn√°ljuk a gyors√≠t√°shoz, a modell konvert√°l√°s√°nak m√≥dj√°t l√°sd a fenti dokument√°ci√≥ban. A `--host` megadja a szolg√°ltat√°s ind√≠t√°si c√≠m√©t, itt `0.0.0.0`-ra van √°ll√≠tva, ami azt jelenti, hogy b√°rmely c√≠mr≈ël el√©rhet≈ë. A `--port` megadja a haszn√°lt portsz√°mot. A `--model_path` megadja a konvert√°lt CTranslate2 modellt. A `--num_workers` megadja, hogy h√°ny sz√°lat haszn√°ljon a p√°rhuzamos k√∂vetkeztet√©shez, ez fontos a webes telep√≠t√©sn√©l, amikor t√∂bb p√°rhuzamos hozz√°f√©r√©s van, egyszerre tud k√∂vetkeztetni. Tov√°bbi param√©terek√©rt tekintse meg ezt a programot.

```shell
python infer_server.py --host=0.0.0.0 --port=5000 --model_path=models/whisper-tiny-finetune-ct2 --num_workers=2
```

### API dokument√°ci√≥

Jelenleg k√©t interf√©sz √©rhet≈ë el: a norm√°l felismer√©si interf√©sz `/recognition` √©s a folyamatos eredm√©nyt visszaad√≥ `/recognition_stream`. Vegye figyelembe, hogy ez a folyamatos m√≥d a felismer√©si eredm√©nyek folyamatos visszaad√°s√°t jelenti, ugyan√∫gy felt√∂lti a teljes hanganyagot, majd folyamatosan adja vissza a felismer√©si eredm√©nyeket. Ez a m√≥dszer nagyon j√≥ √©lm√©nyt ny√∫jt hossz√∫ hanganyagok felismer√©sekor. A dokument√°ci√≥s interf√©szeik teljesen megegyeznek, az interf√©sz param√©terei a k√∂vetkez≈ëk.

|     Mez≈ë     | K√∂telez≈ë |   T√≠pus   |    Alap√©rtelmezett √©rt√©k     |              Le√≠r√°s               |
|:----------:|:----:|:------:|:----------:|:-----------------------------:|
|   audio    |  Igen   |  File  |            |           A felismerend≈ë hangf√°jl            |
| to_simple  |  Nem   |  int   |     1      |            Hagyom√°nyosr√≥l egyszer≈±s√≠tettre v√°lt√°s            |
| remove_pun |  Nem   |  int   |     0      |           √çr√°sjelek elt√°vol√≠t√°sa            |
|    task    |  Nem   | String | transcribe | Felismer√©si feladat t√≠pusa, t√°mogatja a transcribe √©s translate |
|  language  |  Nem   | String |     zh     |    Nyelv be√°ll√≠t√°sa, r√∂vid√≠t√©s, ha None, akkor automatikusan √©szleli a nyelvet     |


Visszat√©r√©si eredm√©ny:

|   Mez≈ë    |  T√≠pus  |      Le√≠r√°s       |
|:-------:|:----:|:-------------:|
| results | list |    Szegment√°lt felismer√©si eredm√©nyek    |
| +result | str  |   Minden szegmens sz√∂veges eredm√©nye   |
| +start  | int  | Minden szegmens kezd√©si ideje, m√°sodpercben |
|  +end   | int  | Minden szegmens befejez√©si ideje, m√°sodpercben |
|  code   | int  |  Hibak√≥d, 0 a sikeres felismer√©s  |

P√©lda:
```json
{
  "results": [
    {
      "result": "Az elm√∫lt √©vekben, nemcsak √©n adtam k√∂nyvet a l√°nyomnak aj√°nd√©kba, hanem a rokonokat √©s bar√°tokat is meggy≈ëztem, hogy ne adjanak p√©nzt a l√°nyomnak, hanem adjanak k√∂nyvet.",
      "start": 0,
      "end": 8
    }
  ],
  "code": 0
}
```

A k√∂nnyebb √©rthet≈ës√©g kedv√©√©rt itt egy Python k√≥d a Web API h√≠v√°s√°hoz, az al√°bbi a `/recognition` h√≠v√°si m√≥dja.
```python
import requests

response = requests.post(url="http://127.0.0.1:5000/recognition",
                         files=[("audio", ("test.wav", open("dataset/test.wav", 'rb'), 'audio/wav'))],
                         json={"to_simple": 1, "remove_pun": 0, "language": "zh", "task": "transcribe"}, timeout=20)
print(response.text)
```

Az al√°bbi a `/recognition_stream` h√≠v√°si m√≥dja.
```python
import json
import requests

response = requests.post(url="http://127.0.0.1:5000/recognition_stream",
                         files=[("audio", ("test.wav", open("dataset/test_long.wav", 'rb'), 'audio/wav'))],
                         json={"to_simple": 1, "remove_pun": 0, "language": "zh", "task": "transcribe"}, stream=True, timeout=20)
for chunk in response.iter_lines(decode_unicode=False, delimiter=b"\0"):
    if chunk:
        result = json.loads(chunk.decode())
        text = result["result"]
        start = result["start"]
        end = result["end"]
        print(f"[{start} - {end}]Ôºö{text}")
```


A megadott tesztoldalak a k√∂vetkez≈ëk:

A f≈ëoldal `http://127.0.0.1:5000/` oldala a k√∂vetkez≈ë:

<div align="center">
<img src="./docs/images/web.jpg" alt="F≈ëoldal" width="600"/>
</div>

A dokument√°ci√≥s oldal `http://127.0.0.1:5000/docs` oldala a k√∂vetkez≈ë:

<div align="center">
<img src="./docs/images/api.jpg" alt="Dokument√°ci√≥s oldal" width="600"/>
</div>


<a name='android-telep√≠t√©s'></a>
## Android telep√≠t√©s

A telep√≠t√©si forr√°sk√≥d az [AndroidDemo](./AndroidDemo) k√∂nyvt√°rban tal√°lhat√≥, a r√©szletes dokument√°ci√≥t a k√∂nyvt√°rban tal√°lhat√≥ [README.md](AndroidDemo/README.md) f√°jlban tal√°lja.
<br/>
<div align="center">
<img src="./docs/images/android2.jpg" alt="Android hat√°sk√©p" width="200">
<img src="./docs/images/android1.jpg" alt="Android hat√°sk√©p" width="200">
<img src="./docs/images/android3.jpg" alt="Android hat√°sk√©p" width="200">
<img src="./docs/images/android4.jpg" alt="Android hat√°sk√©p" width="200">
</div>


<a name='windows-asztali-alkalmaz√°s'></a>
## Windows asztali alkalmaz√°s

A program a [WhisperDesktop](./WhisperDesktop) k√∂nyvt√°rban tal√°lhat√≥, a r√©szletes dokument√°ci√≥t a k√∂nyvt√°rban tal√°lhat√≥ [README.md](WhisperDesktop/README.md) f√°jlban tal√°lja.

<br/>
<div align="center">
<img src="./docs/images/desktop1.jpg" alt="Windows asztali alkalmaz√°s hat√°sk√©p">
</div>



## Referenci√°k

1. https://github.com/huggingface/peft
2. https://github.com/guillaumekln/faster-whisper
3. https://github.com/ggerganov/whisper.cpp
4. https://github.com/Const-me/Whisper
